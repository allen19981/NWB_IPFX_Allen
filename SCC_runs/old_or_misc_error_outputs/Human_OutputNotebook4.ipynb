{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load IPFX libraries\n",
      "from ipfx.dataset.create import create_ephys_data_set\n",
      "from ipfx.data_set_features import extract_data_set_features\n",
      "from ipfx.utilities import drop_failed_sweeps\n",
      "\n",
      "# Load pandas library too\n",
      "import pandas as pd\n",
      "human_data_dict = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipfx.data_access import get_archive_info\n",
      "archive_url, file_manifest, experiment_metadata = get_archive_info(dataset=\"human\")\n",
      "human_specimen_id = list(experiment_metadata['cell_specimen_id'])\n",
      "file_manifest\n",
      "file_name_dict = {}\n",
      "for index, row in file_manifest.iterrows():\n",
      "    if row[\"file_name\"][-4:] == \".nwb\":\n",
      "        file_name_dict[row[\"cell_specimen_id\"]] = row[\"file_name\"]\n",
      "        \n",
      "new_file_name = {}\n",
      "index = 0\n",
      "for item in file_name_dict:\n",
      "    if index > 298:\n",
      "        new_file_name[item] = file_name_dict[item]\n",
      "    index += 1\n",
      "\n",
      "file_name_dict = new_file_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib.request\n",
      "from ipfx.dataset.create import create_ephys_data_set\n",
      "from ipfx.utilities import drop_failed_sweeps\n",
      "\n",
      "for item in file_name_dict:\n",
      "    specimen_id = item\n",
      "    file_name_spec = file_name_dict[item]\n",
      "#     row = file_manifest.query('cell_specimen_id == {} & technique == \"intracellular_electrophysiology\"'.format(specimen_id))\n",
      "#     archive_uri = row['archive_uri'].values[0]\n",
      "#     file_name = row['file_name'].values[0]\n",
      "#     print('Intrinsic ephys file url: ' + archive_uri)\n",
      "#     print('Intrinsic ephys file name: ' + file_name)\n",
      "\n",
      "#     print('downloading data for cell from DANDI...')\n",
      "    try:\n",
      "#         urllib.request.urlretrieve(archive_uri, file_name)\n",
      "#         print('data downloaded!')\n",
      "\n",
      "        # Create Ephys Data Set\n",
      "\n",
      "        print('loading dataset into data structure...')\n",
      "        nwb_file_name = '/external/rprshnas01/netdata_kcni/stlab/AIBS_patchseq_2020/human/ephys/000023/{}'.format(file_name_spec)\n",
      "        data_set = create_ephys_data_set(nwb_file=nwb_file_name) ##loads nwb file into ipfx data structure\n",
      "\n",
      "        # Drop failed sweeps: sweeps with incomplete recording or failing QC criteria\n",
      "        drop_failed_sweeps(data_set)\n",
      "\n",
      "        from ipfx.feature_extractor import SpikeFeatureExtractor, SpikeTrainFeatureExtractor\n",
      "\n",
      "        import ipfx.stimulus_protocol_analysis as spa\n",
      "        from ipfx.epochs import get_stim_epoch\n",
      "        import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "        # get sweep table of Long Square sweeps\n",
      "        long_square_table = data_set.filtered_sweep_table(\n",
      "            stimuli=data_set.ontology.long_square_names\n",
      "        )\n",
      "        long_square_sweeps = data_set.sweep_set(long_square_table.sweep_number)\n",
      "\n",
      "        # Select epoch corresponding to the actual recording from the sweeps\n",
      "        # and align sweeps so that the experiment would start at the same time\n",
      "        long_square_sweeps.select_epoch(\"recording\")\n",
      "        long_square_sweeps.align_to_start_of_epoch(\"experiment\")\n",
      "\n",
      "        # find the start and end time of the stimulus\n",
      "        # (treating the first sweep as representative)\n",
      "        stim_start_index, stim_end_index = get_stim_epoch(long_square_sweeps.i[0])\n",
      "        stim_start_time = long_square_sweeps.t[0][stim_start_index]\n",
      "        stim_end_time = long_square_sweeps.t[0][stim_end_index]\n",
      "\n",
      "        # build the extractors\n",
      "        spfx = SpikeFeatureExtractor(start=stim_start_time, end=stim_end_time)\n",
      "        sptfx = SpikeTrainFeatureExtractor(start=stim_start_time, end=stim_end_time)\n",
      "\n",
      "        # run the analysis and print out a few of the features\n",
      "        long_square_analysis = spa.LongSquareAnalysis(spfx, sptfx, subthresh_min_amp=-100.0)\n",
      "        data = long_square_analysis.analyze(long_square_sweeps)\n",
      "\n",
      "        specimen_dict = summarize_cell_ephys_features(data)\n",
      "        human_data_dict[specimen_id] = specimen_dict\n",
      "        \n",
      "        print(\"{} extracted\".format(item))\n",
      "        dfObj = pd.DataFrame(human_data_dict)\n",
      "        dfObj.to_csv('human_features_from_nwb_local4.csv')\n",
      "        \n",
      "    except urllib.error.HTTPError as err:\n",
      "        print(err.code)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading dataset into data structure...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 20: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 95: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 96: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 97: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 98: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 99: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 111: ['experiment epoch is missing', 'stim epoch is missing']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 146: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 148: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 149: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 150: ['Recording stopped before completing the experiment epoch']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:sweep 153: ['test epoch is missing', 'experiment epoch is missing', 'stim epoch is missing']\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'summarize_cell_ephys_features' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-a817344c31ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlong_square_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlong_square_sweeps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mspecimen_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_cell_ephys_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mhuman_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecimen_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecimen_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'summarize_cell_ephys_features' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}
